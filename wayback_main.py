import pandas as pd
import subprocess
import os
from datetime import datetime


def clean_url(url):
    url = url.strip()           # å»é™¤é¦–å°¾ç©ºæ ¼
    url = url.lower()           # å…¨éƒ¨è½¬å°å†™
    url = url.replace('http://', '').replace('https://', '')  # ç§»é™¤åè®®å¤´
    return url

def read_urls_from_excel(file_path, base_dir="websites"):
    try:
        df = pd.read_excel(file_path)
        urls = [clean_url(url) for url in df.iloc[:, 0].dropna().tolist()]
        urls = list(set(urls))  # å»é‡

        # è·å–å·²ä¸‹è½½çš„ç›®å½•å
        existing_dirs = set(os.listdir(base_dir)) if os.path.exists(base_dir) else set()

        # è¿‡æ»¤å‡ºæœªå¤„ç†çš„URL
        pending_urls = [url for url in urls if url not in existing_dirs]

        # è¾“å‡ºä¸º Excel æ–‡ä»¶
        if pending_urls:
            output_df = pd.DataFrame(pending_urls, columns=["Pending URLs"])
            output_df.to_excel("domains_remain_remain.xlsx", index=False)
            print(f"âœ… æœªå¤„ç†çš„ URL å·²ä¿å­˜è‡³ domains_2_remain.xlsx")
        else:
            print("ğŸ‰ æ‰€æœ‰ URL éƒ½å·²å¤„ç†ï¼Œæ— éœ€è¾“å‡ºæ–‡ä»¶ã€‚")

        return pending_urls, len(urls), len(pending_urls)
    except Exception as e:
        print(f"âŒ è¯»å–Excelæ–‡ä»¶å‡ºé”™: {e}")
        return [], 0, 0

def download_wayback_snapshots(urls):
    base_dir = "websites"
    if not os.path.exists(base_dir):
        os.makedirs(base_dir)

    failed_logs = [] #è®°å½•æ¯æ¬¡è¯·æ±‚å¤±è´¥çš„åŸå› ã€æ–¹ä¾¿åç»­æ’æŸ¥

    for url in urls:
        folder_name = os.path.join(base_dir, url)
        if os.path.isdir(folder_name):
            print(f"â© å·²å­˜åœ¨ç›®å½•ï¼Œè·³è¿‡: {url}")
            continue

        full_url = f"https://{url}"
        command = f'ruby bin/wayback_machine_downloader {full_url} -sl -f 2009 --concurrency 15'
        print(f"âš¡ å¼€å§‹ä¸‹è½½: {full_url}")
        try:
            subprocess.run(command, shell=True, check=True)
            print(f"âœ… ä¸‹è½½å®Œæˆ: {full_url}")
        except subprocess.CalledProcessError as e:
            error_msg = str(e)
            print(f"âš ï¸ ä¸‹è½½å¤±è´¥: {full_url}ï¼Œé”™è¯¯ä¿¡æ¯: {error_msg}")
            failed_logs.append({
                "Time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "URL": url, 
                "Error": error_msg
                })
    
    # ä¿å­˜å¤±è´¥æ—¥å¿—
    if failed_logs:
        df_failed = pd.DataFrame(failed_logs)
        df_failed.to_csv("failed_urls.csv", mode='a', header=not os.path.exists("failed_urls.csv"), index=False, encoding='utf-8-sig')
        print(f"ğŸš¨ å…± {len(failed_logs)} ä¸ªURLä¸‹è½½å¤±è´¥ï¼Œå·²è®°å½•åˆ° failed_urls.csv")
    

if __name__ == "__main__":
    file_name = "domains_remain.xlsx"
    urls, total_count, pending_count = read_urls_from_excel(file_name)
    if urls:
        print(f"ğŸ“Š æ€»URLæ•°: {total_count}ï¼Œå·²å¤„ç†: {total_count - pending_count}ï¼Œå¾…å¤„ç†: {pending_count}")
        download_wayback_snapshots(urls)
    else:
        print("ğŸš¨ æ²¡æœ‰éœ€è¦å¤„ç†çš„URLï¼Œè„šæœ¬ç»“æŸã€‚")